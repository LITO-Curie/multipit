save_name: "test_Cox_PFS_0712"
target: "PFS"


#### Data paths + pre-processing for each modality (e.g. simple imputation)
clinical_data:
  clinical_file: "data/clinicals.csv"
  imputation:
    numericals: [1, 3, 4, 13, 14, 15, 16, 17, 18, 19, -4]
    categoricals: [20, -5, -3]

radiomics_data:
  radiomics_file: "data/radiomics.csv"
  preprocessing:
    f_log_transform: ['TMTV', 'T_TMTV', 'N1_TMTV', 'N2_TMTV', 'N3_TMTV', 'M1a_TMTV', 'M1bc_TMTV']
  imputation:
    numericals: [2]
    categoricals: null

pathomics_data:
  pathomics_file: "data/pathomics.csv"
  imputation:
    numericals: [ 27, 28, 29, 31, 33, 35, 38, 40, 41, 43, 44, 45, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60,
                  61, 62, 63, 64, 65, 66, 67, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,
                  131, 132, 133 ]
    categoricals: null

rna_data:
  rna_file: "data/omics.csv"
  imputation:
    numericals: [32]
    categoricals: null


####  Define survival model + hyperparameters
survival_model:
  type: "Cox"
  args:
    n_alphas: 100
    alpha_min_ratio: 0.01
    l1_ratio: 0.5
#  type: "RF"
#  args:
#    max_features: "sqrt"
#    max_depth: 6

  optim_params: # Uncomment and modify for parameter optimization
#  n_iter_randomcv: 80 # number of iterations/samples for randomsearch


#### Define latefusion parameters (see multipit.multi_model.latefusion)
latefusion:
  n_repeats: 1  # number of repeats for 10-fold cross-validation
  seed: 3 # random seed
  args:
    sup_weights: False # learn weights with inner cross-validation for weighted late fusion
    calibration: True # if True 'calibrate' (i.e. learn standardization) each unimodal model before fusion
    n_jobs: 1
#    tuning: "gridsearch" # uncomment for parameter optimization
#    score: null # uncomment for parameter optimization


##### Additionnal parameters
parallelization:  # number of jobs for dealing with several repeats in parallel (conflict with n_jobs of latefusion)
  n_jobs_repeats: 1

collect_thresholds: True # collect threshold that optimizes log-rank test on the training set

permutation_test: False # perform permutation test
n_permutations: 100